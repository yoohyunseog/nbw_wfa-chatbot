# -*- coding: utf-8 -*-
"""
í”„ë¡¬í”„íŠ¸ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ ëª¨ë“ˆ
gpt_chat_interface.pyì—ì„œ ë¶„ë¦¬ëœ í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ë“¤
"""

import re
import json
import json5
from datetime import datetime


def sanitize_prompt(text: str) -> str:
    """í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ëŠ” í•¨ìˆ˜"""
    return text.replace('\x00', '').strip()[:8000]  # ë„ë¬¸ì ì œê±° + ê¸¸ì´ ì œí•œ


def safe_json_parse(response_text: str, step_name="STEP"):
    """GPT ì‘ë‹µì„ ì•ˆì „í•˜ê²Œ JSONìœ¼ë¡œ íŒŒì‹±í•˜ëŠ” í•¨ìˆ˜"""
    if not response_text or not response_text.strip():
        raise ValueError(f"âŒ {step_name} GPT ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    cleaned = re.sub(r"^```(json)?", "", response_text.strip(), flags=re.MULTILINE)
    cleaned = re.sub(r"```$", "", cleaned, flags=re.MULTILINE).strip()

    if cleaned.startswith("<h2>") or cleaned.startswith("<p>"):
        return {"content": cleaned}

    try:
        return json.loads(cleaned)
    except json.JSONDecodeError as e:
        print(f"âŒ {step_name} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print("ğŸ“„ ì‘ë‹µ ì›ë¬¸ â†“â†“â†“\n", cleaned)
        raise


def build_article_from_existing_structure(user_input: str, clean_trimmed_text: str):
    """ê¸°ì¡´ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    return f"""
    ğŸ§¾ ë‹¤ìŒì€ ê¸°ì‚¬ë‚˜ ë¦¬ë·° ì½˜í…ì¸ ë¡œ í™œìš©ë  ìˆ˜ ìˆëŠ” ì´ˆì•ˆ ì •ë³´ ë˜ëŠ” ìš”ì•½ ë‚´ìš©ì´ì•¼:

    {clean_trimmed_text}...

    ---

    ğŸ¯ ì‚¬ìš©ì ì…ë ¥ ì£¼ì œ: {user_input}

    ---

    ì´ ë‚´ìš©ì„ ë¨¼ì € ë¶„ì„í•´ì„œ, ì „ì²´ ê¸€ì˜ êµ¬ì¡°ì™€ ê°ì • íë¦„ ë˜ëŠ” ì •ë³´ íë¦„ì„ íŒŒì•…í•œ ë’¤, ë‹¤ìŒì„ ìˆ˜í–‰í•´ì¤˜:

    ---

    ğŸ§  ìˆ˜í–‰í•  ì‘ì—…:

    âš ï¸ **ì¤‘ìš” ì£¼ì˜ì‚¬í•­**: 
    - ì œëª©ì´ë‚˜ ë‚´ìš©ì— í‚¤ì›Œë“œê°€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì£¼ì„¸ìš”
    - ìì—°ìŠ¤ëŸ½ê³  ë§¤ë„ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”

    1ï¸âƒ£ `section_titles` êµ¬ì„±  
    ë¬¸ë‹¨ ì œëª©ì€ **"1í¸: [ë‚´ìš©]", "2í¸: [ë‚´ìš©]", "3í¸: [ë‚´ìš©]"** í˜•ì‹ìœ¼ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”.
    
    ì²« ë²ˆì§¸ ë¬¸ë‹¨(1í¸)ì—ëŠ” ì•„ë˜ ì •ë³´ê°€ ê¼­ ë“¤ì–´ê°€ì•¼ í•©ë‹ˆë‹¤:
    - ì¥ë¥´ (ë“œë¼ë§ˆ, ì˜ˆëŠ¥, ì• ë‹ˆë©”ì´ì…˜, ì˜í™” ë“±)
    - ì •ì‹ ì œëª© ë° ì‹œì¦Œ/íšŒì°¨ (ì˜ˆ: ë‚˜ëŠ” ì†”ë¡œ 17ê¸° 4íšŒ)
    - ë°©ì†¡ì‚¬/í”Œë«í¼ (ì˜ˆ: SBS, ENA, Netflix ë“±)
    - ì£¼ìš” ì¸ë¬¼ ë˜ëŠ” ì‹œì²­ í¬ì¸íŠ¸ ê°„ë‹¨ ìš”ì•½
    - ê²Œì„/ëŒ€íšŒ ì •ë³´ (í•´ë‹¹ ì‹œ, ê¼­ í¬í•¨)
    - ì´ë¯¸ì§€ ì—†ëŠ” í¬ìŠ¤íŒ…ì„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì•Œë¦¬ëŠ” ë¬¸ì¥
      (ì˜ˆ: "ì´ë²ˆ ë¦¬ë·°ëŠ” ì˜¤ì§ ê¸€ë¡œë§Œ, ìƒìƒìœ¼ë¡œ ì¥ë©´ì„ ë– ì˜¬ë ¤ë´…ë‹ˆë‹¤." ë“±)

    ì´í›„ ë¬¸ë‹¨ë“¤(2í¸~6í¸)ì€:
    - **ì†Œì„¤ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ì´ì•¼ê¸°**ë¡œ êµ¬ì„±í•´ì£¼ì„¸ìš”
    - ê° í¸ì´ ì´ì „ í¸ì˜ ë‚´ìš©ì„ ë°›ì•„ì„œ ë‹¤ìŒ í¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
    - ë§ˆì¹˜ í•œ í¸ì˜ ì†Œì„¤ì„ ì½ëŠ” ê²ƒì²˜ëŸ¼, ë…ìê°€ ê³„ì†í•´ì„œ ë‹¤ìŒ í¸ì„ ì½ê³  ì‹¶ê²Œ ë§Œë“œëŠ” íë¦„
    - ê° í¸ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì—ì„œ ë‹¤ìŒ í¸ìœ¼ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆëŠ” í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ìš”ì†Œ í¬í•¨
    - ì´ 4~6ê°œì˜ í¸ìœ¼ë¡œ êµ¬ì„± (1í¸ + 3~5ê°œì˜ ì¶”ê°€ í¸)

    ì˜ˆì‹œ í˜•ì‹:
    - "1í¸: [ì£¼ì œ ì†Œê°œ ë° ê¸°ë³¸ ì •ë³´]"
    - "2í¸: [1í¸ì—ì„œ ì´ì–´ì§€ëŠ” í•µì‹¬ ë‚´ìš© ì „ê°œ]"
    - "3í¸: [2í¸ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì„¸ë¶€ ë¶„ì„]"
    - "4í¸: [3í¸ì˜ ë¶„ì„ì„ í† ëŒ€ë¡œ í•œ ê²°ë¡  ë° ë§ˆë¬´ë¦¬]"

    2ï¸âƒ£ `final_title` ìƒì„±  
    - ìœ„ íë¦„ì— ì–´ìš¸ë¦¬ëŠ” **ì™„ì„±ë„ ë†’ì€ ê¸°ì‚¬ ë˜ëŠ” ë¦¬ë·° ì œëª©**ì„ ë§Œë“¤ì–´ì¤˜  
    - ìê·¹ì ì¸ í‘œí˜„ì€ í”¼í•˜ê³ , **ì •ë³´ íë¦„ì„ ìš”ì•½í•˜ë©° ê°ì •ì´ ë¬»ì–´ë‚˜ëŠ” ë¬¸ì¥í˜• ì œëª©**ì´ë©´ ì¢‹ì•„  
    - ë…ìê°€ ì–´ë–¤ ë‚´ìš©ì„ ì½ê²Œ ë ì§€ **ì˜ˆì¸¡ ê°€ëŠ¥í•˜ë©´ì„œë„ ë§¤ë„ëŸ½ê²Œ ì´ë„ëŠ” ì œëª©**
    - ì œëª©ì—ëŠ” ì—°ê´€ í‚¤ì›Œë“œ ë° íƒœê·¸ë¥¼ 2 ~ 3ê°œ í•­ìƒ í¬í•¨ ì‹œì¼œì¤˜
    - **ì¤‘ìš”**: ì œëª©ì— í‚¤ì›Œë“œê°€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ì£¼ì„¸ìš”

    ---

    ğŸ“¦ ìµœì¢… ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´:

    {{
    "section_titles": [
      "1í¸: ALGS Group B, ìˆ¨ë§‰íˆëŠ” ì„œë°”ì´ë²Œì˜ ì„œë§‰",
      "2í¸: ì„œë§‰ì„ ë„˜ì–´ì„  ê²Œì„ì˜ ë£°, ì™œ ë§ˆì§€ë§‰ì— ë°ìŠ¤ë§¤ì¹˜ì²˜ëŸ¼ ë˜ëŠ”ê°€",
      "3í¸: ë°ìŠ¤ë§¤ì¹˜ ì†ì—ì„œ ë¹›ë‚œ FUSN, ìˆœìˆ˜ í•œêµ­ ëŒ€í‘œíŒ€ì˜ ì¡´ì¬ê°",
      "4í¸: FUSNì˜ í™œì•½ ë’¤ì— ìˆ¨ê²¨ì§„ CR ì† ë¦¬ì íŠ¸ ë©¤ë²„ë“¤, êµ­ì ì„ ë„˜ì€ ì „ì¥ì˜ ë™ë£Œë“¤",
      "5í¸: ë™ë£Œë“¤ì˜ ì‘ì› ì†ì—ì„œ ì¼ì–´ë‚œ í•œ í‹±ì˜ ê¸°ì ê³¼ í•œêµ­ íŒ¬ë“¤ì˜ í­ë°œì  ë°˜ì‘",
      "6í¸: ë¦¬ì íŠ¸ëŠ” íƒˆë½í–ˆì§€ë§Œ, ê·¸ë“¤ì´ ë‚¨ê¸´ ì´ì•¼ê¸°ëŠ” ì´ì–´ì§„ë‹¤"
    ],
    "final_title": "ë‚˜ëŠ” ì†”ë¡œ 17ê¸° 4íšŒ, ì •ì  ì†ì—ì„œ í”¼ì–´ë‚œ ê°ì •ì˜ ì§„í­"
    }}
    """


def build_paragraph_prompt(section_title, final_title, user_input, clean_trimmed_text, section_titles, previous_content="", search_engine="bing"):
    """ë¬¸ë‹¨ë³„ ë¸”ë¡œê·¸ ê¸€ ì‘ì„± í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ì „ ë‚´ìš© í¬í•¨, ì¤‘ë³µ ë°©ì§€ ê¸°ëŠ¥ ì¶”ê°€)"""
    # ê²€ìƒ‰ í‚¤ì›Œë“œ ìƒì„± (ì„¹ì…˜ ì œëª©ê³¼ ì‚¬ìš©ì ì…ë ¥ì„ ì¡°í•©)
    search_keywords = f"{section_title} {user_input} {clean_trimmed_text}".strip()
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ê³µë°± ì •ë¦¬
    search_keywords = re.sub(r'[^\w\sê°€-í£]', ' ', search_keywords)
    search_keywords = ' '.join(search_keywords.split())
    
    # ê²€ìƒ‰ ë§í¬ ìƒì„±
    try:
        from utils import generate_search_link
        search_url = generate_search_link(search_keywords, search_engine)
        search_engine_name = search_engine.capitalize()
    except ImportError:
        # utils ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ Bing ë§í¬ ì‚¬ìš©
        from urllib.parse import quote
        if search_engine.lower() == "naver":
            search_url = f"https://search.naver.com/search.naver?query={quote(search_keywords)}"
            search_engine_name = "Naver"
        elif search_engine.lower() == "google":
            search_url = f"https://www.google.com/search?q={quote(search_keywords)}"
            search_engine_name = "Google"
        else:
            search_url = f"https://www.bing.com/search?q={quote(search_keywords)}&sendquery=1&FORM=SCCODX&rh=B0D80A4F&ref=rafsrchae"
            search_engine_name = "Bing"
    
    # ì´ì „ ë‚´ìš©ì´ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš°ë¥¼ êµ¬ë¶„í•˜ì—¬ í”„ë¡¬í”„íŠ¸ ìƒì„±
    if previous_content and previous_content.strip():
        context_instruction = f"""
    ğŸ“š í˜„ì¬ê¹Œì§€ ì‘ì„±ëœ ë‚´ìš©:
    {previous_content[:1000]}{'...' if len(previous_content) > 1000 else ''}
    
    ğŸ“ ì´ì „ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **"{section_title}"** ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    else:
        context_instruction = f"""
    ğŸ“ **"{section_title}"** ë¶€ë¶„ì„ ì²˜ìŒë¶€í„° ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    return f"""
    '{final_title}'ì´ë¼ëŠ” ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì—ì„œ,  
    **"{section_title}"** ë¶€ë¶„ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.{context_instruction}

    ğŸ“š ì „ì²´ ë¬¸ë‹¨ ì£¼ì œ ëª©ë¡: "{section_titles}"  
    ğŸ“ í˜„ì¬ ì‘ì„± ëŒ€ìƒ ë‹¨ë½: "{section_title}"

    ğŸ“Œ ê¸€ ì‘ì„±ì— ì°¸ê³ í•  ê¸°ë°˜ ì •ë³´:
    1. ì‚¬ìš©ì ì…ë ¥ ë‚´ìš©: {user_input}
    2. ìš”ì•½ í‚¤ì›Œë“œ: {clean_trimmed_text}
    3. ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_keywords}

    ğŸ“ ì‘ì„± ê°€ì´ë“œë¼ì¸:
    - ë¬¸ë‹¨ì€ `<p>` íƒœê·¸ë¡œ ê°ì‹¸ê³ , `{section_title}`ì€ `<h2>` íƒœê·¸ë¡œ ë³„ë„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    - **ê²½ì–´ì²´**ì™€ **ì¹œê·¼í•œ ë§íˆ¬**ë¥¼ ì‚¬ìš©í•˜ì—¬ **500ì ì´ë‚´**ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
    - **í•„ìˆ˜ í‚¤ì›Œë“œ**ëŠ” ë¬¸ë§¥ì— ë§ê²Œ 1~2íšŒ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•´ì£¼ì„¸ìš”.
    - **ì¤‘ìš” ë‹¨ì–´ë‚˜ ì¶”ì²œ í‚¤ì›Œë“œì— í•˜ì´í¼ë§í¬**ë¥¼ ì‚½ì…í•˜ê±°ë‚˜, ë¬¸ì¥ íë¦„ì— ë§ì¶°  
      **ê³µì‹ ê²€ìƒ‰ í”Œë«í¼({search_engine_name}, Naver, Google, YouTube)** ë§í¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê±¸ì–´ì£¼ì„¸ìš”.
    - ê²€ìƒ‰ ì—”ì§„: **{search_engine_name}**ì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©í•˜ë˜, í•„ìš”ì‹œ ë‹¤ë¥¸ ê²€ìƒ‰ ì—”ì§„ ë§í¬ë„ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
    
    ğŸ”— ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²° ì§€ì¹¨:
    - ì´ì „ ë‚´ìš©ì´ ìˆë‹¤ë©´, ê·¸ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°›ì•„ì„œ í˜„ì¬ ì„¹ì…˜ìœ¼ë¡œ ì—°ê²°í•´ì£¼ì„¸ìš”.
    - "ì•ì„œ ë§ì”€ë“œë¦°", "ì´ì–´ì„œ", "ê·¸ëŸ°ë°", "í•œí¸" ë“±ì˜ ì—°ê²°ì–´ë¥¼ í™œìš©í•˜ì—¬ ë§¤ë„ëŸ½ê²Œ ì´ì–´ì£¼ì„¸ìš”.
    - ì´ì „ ì„¹ì…˜ì—ì„œ ì–¸ê¸‰ëœ í‚¤ì›Œë“œë‚˜ ê°œë…ì„ í˜„ì¬ ì„¹ì…˜ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ë°œì „ì‹œì¼œì£¼ì„¸ìš”.
    - ë…ìê°€ ì´ì „ ë‚´ìš©ì„ ì½ì—ˆë‹¤ê³  ê°€ì •í•˜ê³ , ì¤‘ë³µ ì„¤ëª…ì€ ìµœì†Œí™”í•˜ë˜ í•„ìš”í•œ ë§¥ë½ì€ ìœ ì§€í•´ì£¼ì„¸ìš”.

    - ë¬¸ì¥ ì‚¬ì´ì—ëŠ” `<br>` íƒœê·¸ë¥¼ ì ì ˆíˆ ë„£ì–´ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.

    ğŸ”— ë§í¬ ì˜ˆì‹œ (êµ¬ì²´ì ì¸ ê²€ìƒ‰ì–´ ì‚¬ìš©):
    ```html
    <p>
    ì´ë²ˆ ì˜¤ì§•ì–´ ê²Œì„ ì‹œì¦Œ3ëŠ” ì „ ì„¸ê³„ì ìœ¼ë¡œ í° í™”ì œë¥¼ ëª¨ìœ¼ê³  ìˆì–´ìš”.<br>
    ê´€ë ¨ ì •ë³´ëŠ” <a href="{search_url}" target="_blank">{search_engine_name} ê²€ìƒ‰</a>ì—ì„œ ë°”ë¡œ í™•ì¸í•´ë³´ì„¸ìš”.<br>
    ë” ìì„¸í•œ ì •ë³´ëŠ” <a href="https://www.youtube.com/results?search_query={search_keywords}" target="_blank">YouTube</a>ì—ì„œë„ ì°¾ì•„ë³¼ ìˆ˜ ìˆì–´ìš”!
    </p>
    ```

    ğŸ” êµ¬ì²´ì ì¸ ê²€ìƒ‰ ë§í¬ ìƒì„± ë°©ë²•:
    - ì„¹ì…˜ ì œëª©: "{section_title}"
    - ì‚¬ìš©ì ì…ë ¥: {user_input}
    - ê²€ìƒ‰ í‚¤ì›Œë“œ: {search_keywords}
    - ì„ íƒëœ ê²€ìƒ‰ ì—”ì§„: {search_engine_name}
    - ì‹¤ì œ ê²€ìƒ‰ URL: {search_url}

    â— í—ˆìš©ë˜ëŠ” ë§í¬ ì¶œì²˜:
    - YouTube (https://www.youtube.com/results?search_query=ê²€ìƒ‰ì–´)
    - Naver (https://search.naver.com/search.naver?query=ê²€ìƒ‰ì–´)
    - Google (https://www.google.com/search?q=ê²€ìƒ‰ì–´)
    - Bing (https://www.bing.com/search?q=ê²€ìƒ‰ì–´&sendquery=1&FORM=SCCODX&rh=B0D80A4F&ref=rafsrchae)

    â›” ì•„ë˜ ì¶œì²˜ëŠ” ì ˆëŒ€ ê¸ˆì§€:
    - ê°œì¸ ë¸”ë¡œê·¸, ê´‘ê³ ì„± í˜ì´ì§€, ë¹„ê³µì‹ ì¶œì²˜ ë“±

    ğŸ“¦ ìµœì¢… ì¶œë ¥ì€ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜:
    {{
      "section_title": "{section_title}",
      "content": "<p>ë¬¸ë‹¨ ë‚´ìš©...</p>"
    }}
    """


def extract_json(text):
    """í…ìŠ¤íŠ¸ì—ì„œ JSON ë¸”ë¡ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    match = re.search(r"\{[\s\S]+\}", text)
    return match.group(0) if match else None


def clean_json_string(raw_text):
    """JSON ë¬¸ìì—´ì„ ì •ì œí•˜ëŠ” í•¨ìˆ˜"""
    # dictì¼ ê²½ìš° ë¬¸ìì—´ë¡œ ì§ë ¬í™”
    if isinstance(raw_text, dict):
        raw_text = json.dumps(raw_text, ensure_ascii=False)

    # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°
    cleaned = re.sub(r"```(?:json)?\s*", "", raw_text)
    cleaned = re.sub(r"\s*```$", "", cleaned)

    # content í•„ë“œ ì „ì²´ ì¶”ì¶œ ë° ì´ìŠ¤ì¼€ì´í”„
    def escape_html_quotes(match):
        content_raw = match.group(1)
        escaped = (
            content_raw
            .replace('\\', '\\\\')
            .replace('"', '\\"')
            .replace('\n', '\\n')
            .replace('\r', '')
        )
        return f'"content": "{escaped}"'

    cleaned = re.sub(
        r'"content"\s*:\s*"([\s\S]+?)"\s*,\s*"(keyword|summary|youtube_keyword)"',
        lambda m: escape_html_quotes(m) + f',\n"{m.group(2)}"',
        cleaned
    )

    return cleaned.strip()


def fix_missing_content_key(json_like_text):
    """title ë‹¤ìŒ ì¤„ì— HTML íƒœê·¸ë¡œ ì‹œì‘í•˜ëŠ” ë¸”ë¡ì´ content í‚¤ ì—†ì´ ë“±ì¥í•  ê²½ìš° content í‚¤ë¥¼ ì‚½ì…"""
    pattern = r'("final_title"\s*:\s*".+?"),\s*("(<h[1-6]>|<p>|<div>|<ul>|<blockquote>|<section>|<article>))'
    fixed_text = re.sub(pattern, r'\1,\n"content": \2', json_like_text, flags=re.DOTALL)
    return fixed_text


def generate_filename():
    """í˜„ì¬ ë‚ ì§œì™€ ì‹œê°„ì„ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ ì´ë¦„ ìƒì„±"""
    return datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + "_huggingface_demo_img.png"


def generate_gpt_prompt_from_html(html_content, auto_generate_available=False, generate_prompts_with_gpt_func=None):
    """
    HTML ì½˜í…ì¸ ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GPT í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        html_content (str): HTML íƒœê·¸ê°€ í¬í•¨ëœ ì½˜í…ì¸ 
        auto_generate_available (bool): auto_generate_data_json ëª¨ë“ˆ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        generate_prompts_with_gpt_func (function): generate_prompts_with_gpt í•¨ìˆ˜
        
    Returns:
        str: ìƒì„±ëœ GPT í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸
    """
    try:
        # HTML íƒœê·¸ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        clean_text = re.sub(r'<[^>]+>', '', html_content)
        clean_text = re.sub(r'\s+', ' ', clean_text).strip()
        
        # ê¸°ì¡´ generate_prompts_with_gpt í•¨ìˆ˜ ì‚¬ìš©
        if auto_generate_available and generate_prompts_with_gpt_func:
            print(f"ğŸ¤– GPTë¡œ '{clean_text[:100]}...' ì£¼ì œì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            try:
                generated_prompts = generate_prompts_with_gpt_func(clean_text, num_prompts=1)
                if generated_prompts and len(generated_prompts) > 0:
                    first_prompt = generated_prompts[0]
                    if isinstance(first_prompt, dict) and 'content' in first_prompt:
                        gpt_prompt = first_prompt['content']
                        print(f"âœ… GPT ìƒì„± í”„ë¡¬í”„íŠ¸: {gpt_prompt[:100]}...")
                        return gpt_prompt
                    elif isinstance(first_prompt, str):
                        gpt_prompt = first_prompt
                        print(f"âœ… GPT ìƒì„± í”„ë¡¬í”„íŠ¸: {gpt_prompt[:100]}...")
                        return gpt_prompt
                    else:
                        print("âš ï¸ í”„ë¡¬í”„íŠ¸ í˜•ì‹ ì˜¤ë¥˜, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                        return clean_text
                else:
                    print("âš ï¸ GPT í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                    return clean_text
            except Exception as e:
                print(f"âš ï¸ GPT í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
                return clean_text
        else:
            print("âš ï¸ auto_generate_data_json ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
            return clean_text
    except Exception as e:
        print(f"âŒ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return html_content


def build_category_prompt_with_system(title, content):
    """ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # CATEGORY_LISTì—ì„œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ
    category_info = []
    for item in CATEGORY_LIST:
        category_info.append(f"- {item['ca_name']}: {item['ca_description']}")
    
    category_list_text = "\n    ".join(category_info)
    
    system_prompt = f"""ë‹¹ì‹ ì€ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì£¼ì–´ì§„ ì œëª©ê³¼ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.
    
    ì¹´í…Œê³ ë¦¬ ëª©ë¡:
    {category_list_text}
    
    ì‘ë‹µì€ ë°˜ë“œì‹œ ì¹´í…Œê³ ë¦¬ëª…ë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”."""
    
    user_prompt = f"ì œëª©: {title}\në‚´ìš©: {content[:500]}..."
    
    return system_prompt, user_prompt, CATEGORY_LIST 

# ì¹´í…Œê³ ë¦¬ ëª©ë¡ ìƒìˆ˜
CATEGORY_LIST = [
    {"ca_name": "AMERICAAI", "ca_description": "ë¯¸êµ­ ì¤‘ì‹¬ì˜ AI ì •ì±…, ê¸°ìˆ  ë™í–¥ ë° êµ­ê°€ ì „ëµ ë¶„ì„, ë¯¸êµ­ ê´€ë ¨ ëª¨ë“  ì†Œì‹"},
    {"ca_name": "EUAI", "ca_description": "ìœ ëŸ½ì—°í•© AI ê·œì œ, ìœ¤ë¦¬ì  ê¸°ì¤€ ë° EU AI Act ê´€ë ¨ ì •ë³´"},
    {"ca_name": "Organizers", "ca_description": "í–‰ì‚¬ ì£¼ìµœì ë° ì¡°ì§ ê´€ë ¨ íŠ¸ë Œë“œ ë° ì¸ë¬¼ ì •ë³´"},
    {"ca_name": "Courses", "ca_description": "ì˜¨ë¼ì¸/ì˜¤í”„ë¼ì¸ êµìœ¡ ê³¼ì • ë° í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ ì •ë³´"},
    {"ca_name": "DramaDetails", "ca_description": "êµ­ë‚´ì™¸ ë“œë¼ë§ˆì˜ ì¤„ê±°ë¦¬, ë°°ìš° ì •ë³´ ë° ì‹œì²­ íŠ¸ë Œë“œ"},
    {"ca_name": "anime", "ca_description": "ì¼ë³¸ ì• ë‹ˆë©”ì´ì…˜ ì‹ ì‘ ì •ë³´, ë¦¬ë·°, íŒ¬ë¤ ë°˜ì‘, ì›¹íˆ°"},
    {"ca_name": "GameNews", "ca_description": "êµ­ë‚´ì™¸ ìµœì‹  ê²Œì„ ì†Œì‹ ë° ì—…ë°ì´íŠ¸ ì •ë³´"},
    {"ca_name": "PokemonBread", "ca_description": "í¬ì¼“ëª¬ë¹µ êµ¿ì¦ˆ, ë ë¶€ë ë¶€ì”° ë° ìˆ˜ì§‘ ì •ë³´"},
    {"ca_name": "EconomicIndicators", "ca_description": "ì£¼ìš” ê²½ì œ ì§€í‘œ ë° ê¸€ë¡œë²Œ ê¸ˆìœµ ë™í–¥"},
    {"ca_name": "entertainment", "ca_description": "ì—°ì˜ˆê³„ ì „ë°˜ì˜ ë‰´ìŠ¤, ì´ìŠˆ, ìŠ¤íƒ€ ë™í–¥"},
    {"ca_name": "entertainmentnews", "ca_description": "ì—°ì˜ˆê³„ ì†ë³´ ì¤‘ì‹¬ì˜ ë‰´ìŠ¤ ì½˜í…ì¸ "},
    {"ca_name": "movie", "ca_description": "ì‹ ì‘ ì˜í™”, ë°•ìŠ¤ì˜¤í”¼ìŠ¤, ê°ë… ë° ë°°ìš° ì •ë³´"},
    {"ca_name": "sports", "ca_description": "êµ­ë‚´ì™¸ ìŠ¤í¬ì¸  ê²½ê¸° ê²°ê³¼ ë° ì„ ìˆ˜ ì´ìŠˆ"},
    {"ca_name": "car", "ca_description": "ìë™ì°¨ ì¶œì‹œ, ì‹œìŠ¹ê¸°, ë¸Œëœë“œ ë¹„êµ ì •ë³´"},
    {"ca_name": "TourSpots", "ca_description": "êµ­ë‚´ì™¸ ì—¬í–‰ì§€ ì¶”ì²œ, ì²´í—˜ê¸° ë° ê´€ê´‘ ì •ë³´"},
    {"ca_name": "robot", "ca_description": "ë¡œë´‡ ê¸°ìˆ , ì‚°ì—… ë™í–¥ ë° ìƒí™œ ì† ë¡œë´‡ í™œìš©, ì»´í“¨í„° ë¶€í’ˆ í¬í•¨"},
    {"ca_name": "politics", "ca_description": "êµ­ë‚´ì™¸ ì •ì¹˜ ë‰´ìŠ¤ ë° ì •ì±… ë¶„ì„"},
    {"ca_name": "RecommendedVideo", "ca_description": "AI ê¸°ë°˜ ì¶”ì²œ ì˜ìƒ ë° ìœ íŠœë¸Œ í•« ì½˜í…ì¸ "},
    {"ca_name": "x_file", "ca_description": "ë¯¸ìŠ¤í„°ë¦¬, ìŒëª¨ë¡ , UFO ë“± ê¸°ì´í•œ ì •ë³´ ì½˜í…ì¸ "},
    {"ca_name": "8bit", "ca_description": "ë³µê³ í’ 8ë¹„íŠ¸ ê²Œì„, ì•„íŠ¸, ìŒì•… ê´€ë ¨ ì½˜í…ì¸ "},
    {"ca_name": "UserQueryLog", "ca_description": "ì‚¬ìš©ì ì§ˆì˜ ê¸°ë°˜ ì¶”ì²œ í‚¤ì›Œë“œ ë° ë¶„ì„ ê²°ê³¼"},
    {"ca_name": "CosmeticBrandsInfo", "ca_description": "í™”ì¥í’ˆ ë¸Œëœë“œë³„ íŠ¸ë Œë“œ, ì œí’ˆ ë¦¬ë·° ì •ë³´"},
    {"ca_name": "FashionMakersList", "ca_description": "êµ­ë‚´ì™¸ íŒ¨ì…˜ ë””ìì´ë„ˆ ë° ë¸Œëœë“œ ì •ë³´"},
    {"ca_name": "mobilegame", "ca_description": "ëª¨ë°”ì¼ ê²Œì„ ì¶œì‹œ ì •ë³´ ë° ì‚¬ìš©ì ë¦¬ë·°"},
    {"ca_name": "DongmyoFashionHub", "ca_description": "ë™ë¬˜ íŒ¨ì…˜ íŠ¸ë Œë“œ, ê±°ë¦¬ íŒ¨ì…˜ ë° ì¸ê¸° ìƒí’ˆ ì •ë³´"},
    {"ca_name": "stock", "ca_description": "ì£¼ì‹ì‹œì¥ ë™í–¥, ì¢…ëª© ë¶„ì„ ë° íˆ¬ì ì „ëµ"},
    {"ca_name": "googleApp", "ca_description": "Google Play ì•± ì¶”ì²œ, ë¦¬ë·° ë° ìˆœìœ„ ì •ë³´"},
    {"ca_name": "googleBook", "ca_description": "Google ë„ì„œ í”Œë«í¼ ê¸°ë°˜ ì¶”ì²œ ì±… ë° ë¶„ì„"},
    {"ca_name": "googleKids", "ca_description": "Google Kidsìš© ì½˜í…ì¸ , êµìœ¡ ì•± ì •ë³´"},
    {"ca_name": "googleComics", "ca_description": "Google í”Œë«í¼ ê¸°ë°˜ ì›¹íˆ°/ì½”ë¯¹ìŠ¤ ì½˜í…ì¸  ì†Œê°œ"},
    {"ca_name": "Semiraepaong", "ca_description": "ì„¸ë¯¸ë¼ì—íŒŒì˜¹ ê´€ë ¨ ì´ìŠˆ ë˜ëŠ” íŠ¹ì • ê¸°íš ì½˜í…ì¸ "},
    {"ca_name": "LiveGameStreams", "ca_description": "ì‹¤ì‹œê°„ ê²Œì„ ìŠ¤íŠ¸ë¦¬ë° ì±„ë„ ë° ì¸ê¸° í´ë¦½"},
    {"ca_name": "PsychologyResources", "ca_description": "ì‹¬ë¦¬í•™ ê¸°ë°˜ ë¦¬ì†ŒìŠ¤, í…ŒìŠ¤íŠ¸, ì •ì‹  ê±´ê°• ì½˜í…ì¸ "},
    {"ca_name": "CommGuide", "ca_description": "ì§€ì—­ ì»¤ë®¤ë‹ˆí‹° ì•ˆë‚´, ì´ìš© ê·œì¹™, ìš´ì˜ ê°€ì´ë“œ"},
    {"ca_name": "usa", "ca_description": "ë¯¸êµ­ ì‚¬íšŒ, ê²½ì œ, ë¬¸í™” ê´€ë ¨ íŠ¸ë Œë“œì™€ ë¶„ì„"},
    {"ca_name": "afreecatv", "ca_description": "ì•„í”„ë¦¬ì¹´TV ì¸ê¸° ë°©ì†¡, BJ íŠ¸ë Œë“œ ë° ì½˜í…ì¸  ë¶„ì„"}
] 